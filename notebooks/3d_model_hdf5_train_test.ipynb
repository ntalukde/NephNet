{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from data_loader import data_loaders as module_data\n",
    "from model import loss as module_loss\n",
    "from model import metric as module_metric\n",
    "from model import model as module_arch\n",
    "from trainer import Trainer\n",
    "from utils import Logger\n",
    "from utils import util\n",
    "from utils import torchsummary\n",
    "from utils import viewTraining\n",
    "from utils import lr_finder\n",
    "from utils import classActivationMap\n",
    "import importlib\n",
    "import math\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "import skimage.transform\n",
    "import jupyter\n",
    "from IPython import display\n",
    "print(\"Modules loaded\")\n",
    "\n",
    "importlib.reload(module_data) #load recent changes to data_loaders.py\n",
    "importlib.reload(module_arch)\n",
    "importlib.reload(module_loss)\n",
    "importlib.reload(module_metric)\n",
    "importlib.reload(util)\n",
    "importlib.reload(viewTraining)\n",
    "importlib.reload(lr_finder)\n",
    "importlib.reload(classActivationMap)\n",
    "print(\"Reload complete\")\n",
    "\n",
    "print(\"GPUs available: \" + str(torch.cuda.device_count()))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.keyboard_manager.disable();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/config_hdf5.json'\n",
    "\n",
    "# load config file\n",
    "with open(config_file) as handle:\n",
    "    config = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This function gets the parameters from the config.json file \n",
    "def get_instance(module, name, config, *args):\n",
    "    return getattr(module, config[name]['type'])(*args, **config[name]['args'])\n",
    "    \n",
    "data_loader = get_instance(module_data, 'data_loader', config) #looks in data_loader/data_loaders.py for 'MNISTDataLoader'\n",
    "print(\"Total number of training images = \" + str(data_loader.dataset.data_len))\n",
    "data_loader_test = get_instance(module_data, 'data_loader_test', config) #looks in data_loader/data_loaders.py for 'MNISTDataLoader'\n",
    "print(\"Total number of testing images = \" + str(data_loader_test.dataset.data_len))\n",
    "\n",
    "normalized = False\n",
    "util.visualizeBatch(data_loader, normalized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_instance(module, name, config, *args):\n",
    "    setattr(module, config[name]['type'])(*args, **config[name]['args'])\n",
    "    \n",
    "# setting path to save trained models and log files\n",
    "path = os.path.join(config['trainer']['save_dir'], config['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config, resume):\n",
    "    train_logger = Logger() #uses entries to store training performance metrics\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # setup data_loader instances\n",
    "    data_loader = get_instance(module_data, 'data_loader', config) #looks in data_loader/data_loaders.py for 'MNISTDataLoader'\n",
    "    print(\"Total number of training images = \" + str(data_loader.dataset.data_len))\n",
    "    valid_data_loader = data_loader.split_validation() #allocate some images as validation\n",
    "\n",
    "    # build model architecture\n",
    "    model = get_instance(module_arch, 'arch', config) #looks in the model/model.py for 'MnistModel', as specified by config\n",
    "    print(model)\n",
    "    #torchsummary.summary(model, (1,7,32,32))\n",
    "     \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using GPU: \" + torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print(\"Using CPU to train\")\n",
    "    \n",
    "    # get function handles of loss and metrics\n",
    "    loss = getattr(module_loss, config['loss']) #looks in model/loss.py for criterion function specified in config\n",
    "    criterion = loss(data_loader.dataset.weight.to(device)) # for imbalanced datasets\n",
    "    metrics = [getattr(module_metric, met) for met in config['metrics']] #get all the metrics in model/metrics.py - default is accuracy and top 3 accuracy\n",
    "\n",
    "    # build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters()) #Number of training params\n",
    "    optimizer = get_instance(torch.optim, 'optimizer', config, trainable_params)\n",
    "    lr_scheduler = get_instance(torch.optim.lr_scheduler, 'lr_scheduler', config, optimizer)\n",
    "\n",
    "    \n",
    "    trainer = Trainer(model, criterion, metrics, optimizer,\n",
    "                      resume=resume, #choose a previous epoch to start training from\n",
    "                      config=config,\n",
    "                      data_loader=data_loader,\n",
    "                      valid_data_loader=valid_data_loader,\n",
    "                      lr_scheduler=lr_scheduler,\n",
    "                      train_logger=train_logger)\n",
    "    \n",
    "    findLR = False\n",
    "    if findLR:\n",
    "        #set lr = 1e-7 in config file \n",
    "        device_lr = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        lr_finder_training = lr_finder.LRFinder(model, optimizer, criterion, device=device_lr)\n",
    "        lr_finder_training.range_test(data_loader, end_lr=1, num_iter=100, val_loader = valid_data_loader)\n",
    "        lr_finder_training.plot(skip_start = 10, skip_end=5)\n",
    "        # trim the first 10 and last 5 iteration from calculating loss (num_iter > skip_start + skip_end)\n",
    "    else:\n",
    "        trainer.train()\n",
    "        a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "main(config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture\n",
    "model = get_instance(module_arch, 'arch', config)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "normalized = False\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "loss_fn = getattr(module_loss, config['loss'])\n",
    "criterion = loss_fn(None)\n",
    "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
    "\n",
    "# load state dict\n",
    "checkpoint = torch.load(resume)\n",
    "checkpoint_state_dict = checkpoint['state_dict']\n",
    "for key in list(checkpoint_state_dict.keys()):\n",
    "    if 'module.' in key:\n",
    "        checkpoint_state_dict[key.replace('module.', '')] = checkpoint_state_dict[key]\n",
    "        del checkpoint_state_dict[key]\n",
    "model.load_state_dict(checkpoint_state_dict)\n",
    "\n",
    "# prepare model for testing\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(config, resume, data_loader):\n",
    "    \n",
    "    model.eval() #tells model to ignore dropout and batch normalization\n",
    "    total_loss = 0.0\n",
    "    total_metrics = torch.zeros(len(metric_fns))\n",
    "    \n",
    "    classes = ('pt', 'tal')\n",
    "    all_pred = []\n",
    "    all_true = []\n",
    "    all_softmax = []\n",
    "    \n",
    "    with torch.no_grad(): #speed up calculations, unable to perform back propogation\n",
    "        for i, (data, target) in enumerate(tqdm(data_loader)): #tqdm is a progress bar\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            image = np.squeeze(data[0].cpu().data.numpy())\n",
    "            label = np.squeeze(target[0].cpu().data.numpy())\n",
    "            all_true.extend(target.cpu().data.numpy())\n",
    "            all_pred.extend(np.argmax(output.cpu().data.numpy(), axis=1))\n",
    "            \n",
    "            m = torch.nn.Softmax(dim=0)\n",
    "            for i,row in enumerate(output.cpu()):\n",
    "                sm = m(row)\n",
    "                all_softmax.append(sm.data.numpy())\n",
    "              \n",
    "            if i < 2:\n",
    "                m = torch.nn.Softmax(dim=0)\n",
    "                \n",
    "            # computing loss, metrics on test set\n",
    "            loss = criterion(output, target)\n",
    "            batch_size = data.shape[0]\n",
    "            total_loss += loss.item() * batch_size\n",
    "            if output.is_cuda: output = output.cpu()\n",
    "            if target.is_cuda: target = target.cpu()\n",
    "            \n",
    "            for i, metric in enumerate(metric_fns):\n",
    "                total_metrics[i] += metric(output.cpu(), target) * batch_size\n",
    "    \n",
    "    outputcsv = False\n",
    "    if outputcsv:\n",
    "        ids = data_loader.dataset.getIds()\n",
    "        softmax = pd.DataFrame(all_softmax)\n",
    "        all_true_for_outputcsv = [x+1 for x in all_true]\n",
    "        frames = [ids, softmax, pd.DataFrame(all_true_for_outputcsv)]\n",
    "        output_data= np.concatenate(frames, axis=1)\n",
    "        print(output_data.shape)\n",
    "        output_df = pd.DataFrame(output_data)\n",
    "        output_df.to_csv('overlaycsv.csv', index=False,  header=False)\n",
    "        \n",
    "    n_samples = len(data_loader.sampler)\n",
    "    print(\"num test images = \" + str(n_samples))\n",
    "    log = {'loss': total_loss / n_samples}\n",
    "    log.update({met.__name__: total_metrics[i].item() / n_samples for i, met in enumerate(metric_fns)})\n",
    "    for key in log:\n",
    "        print(\"{} = {:.4f}\".format(key, log[key]))\n",
    "    log['classes'] = classes\n",
    "    log['test_targets'] = all_true\n",
    "    log['test_predictions'] = all_pred\n",
    "    print(\"My_metric is accuracy\")\n",
    "    util.plot_confusion_matrix(all_true, all_pred, classes=classes, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup data_loader instances\n",
    "data_loader = get_instance(module_data, 'data_loader_test', config)\n",
    "#Test\n",
    "main2(config, resume, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
